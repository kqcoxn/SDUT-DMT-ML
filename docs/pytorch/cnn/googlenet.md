# GooLeNet

## 含并行连结的网络

GoogLeNet 吸收了 NiN 中串联网络的思想，并在此基础上做了改进。我们往往不确定到底选取什么样的层效果更好，到底是 3X3 卷积层还是 5X5 的卷积层，诸如此类的问题是 GooLeNet 选择了另一种思路“小学生才做选择，我全都要”，这也使得 GooLeNet 成为了第一个模型中超过 1000 个层的模型。

## Inception 块

在 GoogLeNet 中，基本的卷积块被称为 Inception 块（Inception block）

![](../images/cnn/27-1.png)

Inception 块由四条并行路径组成。 前三条路径使用窗口大小为 1×11×1、3×33×3 和 5×55×5 的卷积层，从不同空间大小中提取信息。 中间的两条路径在输入上执行 1×11×1 卷积，以减少通道数，从而降低模型的复杂性。 第四条路径使用 3×33×3 最大汇聚层，然后使用 1×11×1 卷积层来改变通道数。 这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成 Inception 块的输出。在 Inception 块中，通常调整的超参数是每层输出通道数。

## GooLeNet 模型

GoogLeNet 一共使用 9 个 Inception 块和全局平均汇聚层的堆叠来生成其估计值。Inception 块之间的最大汇聚层可降低维度。 第一个模块类似于 AlexNet 和 LeNet，Inception 块的组合从 VGG 继承，全局平均汇聚层避免了在最后使用全连接层。

![](../images/cnn/27-2.png)

其中：

- 第一个模块是 7×7 卷积层。
- 第二个模块使用两个卷积层：第一个卷积层是 1×1 卷积层；第二个卷积层使用将通道数量增加三倍的 3×3 卷积层。 这对应于 Inception 块中的第二条路径。
- 第三个模块串联两个完整的 Inception 块。 第一个 Inception 块的输出通道数为 64+128+32+32=25664+128+32+32=256，四个路径之间的输出通道数量比为 64:128:32:32=2:4:1:164:128:32:32=2:4:1:1。 第二个和第三个路径首先将输入通道的数量分别减少到 96/192=1/296/192=1/2 和 16/192=1/1216/192=1/12，然后连接第二个卷积层。第二个 Inception 块的输出通道数增加到 128+192+96+64=480128+192+96+64=480，四个路径之间的输出通道数量比为 128:192:96:64=4:6:3:2128:192:96:64=4:6:3:2。 第二条和第三条路径首先将输入通道的数量分别减少到 128/256=1/2128/256=1/2 和 32/256=1/832/256=1/8。
- 第四模块更加复杂， 它串联了 5 个 Inception 块，其输出通道数分别是 192+208+48+64=512192+208+48+64=512、160+224+64+64=512160+224+64+64=512、128+256+64+64=512128+256+64+64=512、112+288+64+64=528112+288+64+64=528 和 256+320+128+128=832256+320+128+128=832。 这些路径的通道数分配和第三模块中的类似，首先是含 3×3 卷积层的第二条路径输出最多通道，其次是仅含 1×1 卷积层的第一条路径，之后是含 5×5 卷积层的第三条路径和含 3×3 最大汇聚层的第四条路径。 其中第二、第三条路径都会先按比例减小通道数。 这些比例在各个 Inception 块中都略有不同。
